Text extraction is the process of extracting key sentences from the original text without changing the sequence of words within the sentence. TextRank is a graph-based algorithm that is best suited for this purpose. TextRank was developed by Mihalcea, Rada, and Paul Tarau in 2004, and it is based on the famous PageRank algorithm that Google uses to rank webpages in its search engine [16]. The underlying principle of this algorithm is to assign a similarity score to each sentence in the text, and then take the top ranked sentences to form a summary of the document. The first step in the process is to tokenize the given text into sentences, which is typically done using a tokenizer from a NLP library. However, one can also implement a function that uses the dot or newline characters to tokenize. Next, stop words such as ‘the’, ‘and’, and ‘at’ are removed from each sentence, because these words appear in almost every sentence, which will skew the results. All popular machine learning libraries contain a complete list of stop words in the English language. Then a graph is constructed in which the nodes represent the sentences and the links between nodes represent the similarity score between the sentences. The similarity score can be calculated using a variety of methods that can be based on relatively simple to complex formulas. For example, one method to compute similarity between two sentences is to find the number of common words between the two sentences and divide that number by the total number of words. The more widely accepted method in text extraction uses the cosine function to compute the similarity between two sentences. In mathematics, the cosine for two non-zero vectors can be calculated using the Euclidean dot product formula, which is shown below. However, for this approach to work in text extraction, cosine similarity is computed for pairs of sentences within the text on a one-by-one basis. The two sentences under consideration are converted to vectors of the same length using the process shown in Figure 5 [17].